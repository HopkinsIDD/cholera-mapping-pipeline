---
title: "Data and Model Outputs Report"
output: html_document
params: 
  cholera_directory: "C:/IDD/Cholera/commit_git/cholera-mapping-pipeline"
  config: "/Analysis/configs/config_TGO_2015_2019_censoring_prior.yml"
  drop_nodata_years: TRUE
  admin_level_for_summary_table: '1'
  args: 'myarg'
  old_runs: FALSE
---
```{r setup, include=FALSE, dev="CairoPNG"}
library(knitr)
knitr::opts_chunk$set(
  cache=TRUE,
  cache.lazy = FALSE,
  echo = FALSE,
  dev="CairoPNG",
  error = FALSE,
  fig.align = "center",
  message = TRUE,
  warning = TRUE
  )
library(stringr)
library(dplyr)
library(magrittr)
library(purrr)
library(readr)
library(ggplot2)
library(kableExtra)
library(taxdat)
library(sf)
library(raster)
library(stars)
sf::sf_use_s2(FALSE)
library(taxdat)


### other new packages (mainly for "rgeoboundaries")
chooseCRANmirror(ind = 77)

package_list <- c(
  "fasterize", 
  "remotes",
  "rgeoboundaries"
)

for (package in package_list) {
  if (!require(package = package, character.only = T)) {
    if (package == "rgeoboundaries"){
      try({
        remotes::install_gitlab("dickoa/rgeoboundaries")
        remotes::install_github("wmgeolab/rgeoboundaries")
      })
    }else{
      install.packages(pkgs = package)
      library(package = package, character.only = T)
    }
  }
}


#Figure Caption Numbering,
capFigNo = 1
#Function to add the Figure Number
capFig = function(x){
    x = paste0("Figure ",capFigNo,". ",x)
    capFigNo <<- capFigNo + 1
    x
}

```

# Mapping results summary for `r stringr::str_extract(params$config, "[A-Z]{3}")` and period `r stringr::str_extract(params$config, "[0-9]{4}_[0-9]{4}")`

## Cholera input data
**Data input:**
```{r load data}
# Load data
cache<-new.env()

get_stan_input(name="stan_input",
               cache=cache,
               config = paste0(params$cholera_directory, params$config), 
               cholera_directory = params$cholera_directory)
get_sf_cases_resized(
                    name="sf_cases_resized",
                    cache=cache,
                    config = paste0(params$cholera_directory, params$config),
                    cholera_directory = params$cholera_directory)

get_sf_cases(name="sf_cases",
             cache=cache,
             config=paste0(params$cholera_directory, params$config),
             cholera_directory=params$cholera_directory)

####stan output file name contains invalid characters in windows, so manually edit the stan output file name############
get_model_rand_no_cache <- function(config, cache, cholera_directory) {
  config <- yaml::read_yaml(config)
  file_names <- taxdat::get_filenames(config, cholera_directory)
  file_names[["stan_output"]]<-"C:/IDD/Cholera/commit_git/cholera-mapping-pipeline/Analysis/data/TGO_stan_output.rdata"
  model.rand <- taxdat::read_file_of_type(file_names[["stan_output"]], "model.rand")
  require(bit64)
  require(sf)
  return(model.rand)
}
# cache the results
get_model_rand <- cache_fun_results(name = "model.rand", fun = get_model_rand_no_cache,
                                    overwrite = T, config = config)
####################

get_model_rand(name="model.rand",
               cache=cache,
               config = paste0(params$cholera_directory,params$config), 
               cholera_directory = params$cholera_directory)


get_modeled_cases(name="modeled_cases",
                  cache=cache,
                  config = paste0(params$cholera_directory, params$config),
                  cholera_directory = params$cholera_directory)




get_modeled_rates(name="modeled_rates",
                  cache=cache,
                  config = paste0(params$cholera_directory, params$config),
                  cholera_directory = params$cholera_directory
)

cache[["modeled_cases_by_chain"]]<-aggregate_modeled_cases_by_chain_no_cache(
                                 cache=cache,
                                 config = paste0(params$cholera_directory, params$config),
                                 cholera_directory = params$cholera_directory
                                 )


cache[["cases_chains"]]<-aggregate_modeled_cases_by_chain_gridtime_no_cache(
                                          cache=cache,
                                 config = paste0(params$cholera_directory, params$config),
                                 cholera_directory = params$cholera_directory)


#stan_output <- lapply(rstan::extract(cache[["model.rand"]]), function(x){array(x,c(niter_per_chain, nchain, dim(x)[-1]))})
cache[["niter_per_chain"]]<-get_stan_model_niter_per_chain_no_cache(cache=cache,
                                 config = paste0(params$cholera_directory, params$config),
                                 cholera_directory = params$cholera_directory)
cache[["nchain"]]<-get_stan_model_nchain_no_cache(cache=cache,
                                 config = paste0(params$cholera_directory, params$config),
                                 cholera_directory = params$cholera_directory)
cache[["stan_output"]]<-get_stan_output_no_cache(cache=cache,
                                 config = paste0(params$cholera_directory, params$config),
                                 cholera_directory = params$cholera_directory)

  
get_initial_values(name="initial_values_data",
                  cache=cache,
                  config = paste0(params$cholera_directory, params$config),
                  cholera_directory = params$cholera_directory)

cache[["gam_output_df"]]<-get_gam_values_no_cache(
                  cache=cache,
                  config = paste0(params$cholera_directory, params$config),
                  cholera_directory = params$cholera_directory)
  
names(cache)
```

## GAM Input
**Observations input for the GAM model:**
```{r gam input,fig.cap=capFig("Observations input for the GAM model")}
plot_gam_fit_input_cases (name="initial_values_data",cache=cache)
plot_gam_fit_input_rates (name="initial_values_data",cache=cache)
```


# GAM Output
**Observations input for the GAM model:**
```{r gam output,fig.cap=capFig("Observations input for the GAM model")}
  plot_gam_fit_output_cases(name="gam_output_df",cache=cache)
  plot_gam_fit_output_rates(name="gam_output_df",cache=cache)
```


**Table 1. Data used within the model:**
```{r cases}
if(!is.null(cache[["sf_cases_resized"]])){
  plot_ObservationSummary_table(config=params$config, cache=cache, cholera_directory=params$cholera_directory)
} else{
  warning("sf_cases_resized is NULL")
}

```

**Table 2. Data dropped from the model:**
```{r dropcases}
### 11/02/2021 update -- dropped = all - used
if(!is.null(cache[["sf_cases"]]) & !is.null(cache[["sf_cases_resized"]])){
  plot_DroppedData_table (config=params$config, cache=cache, cholera_directory=params$cholera_directory)
} else{
  warning("sf_cases or sf_cases_resized is NULL")
}

```

```{r disjoint set sf cases}
aggregate_observed_polygon_cases_disjoint_aggregated(name="observed_polygon_cases_disjoint_aggregated",
                                                     config=params$config,
                                                     cholera_directory=params$cholera_directory,
                                                     cache=cache)

disjoint_set_sf_cases <- cache[["observed_polygon_cases_disjoint_aggregated"]]
colnames(disjoint_set_sf_cases)
```

**Cases by time:**
```{r rawobsmap, fig.height=5, fig.width=10, fig.cap=capFig("Observed case counts by time adjusted for time fraction cases/year")}
if(!is.null(disjoint_set_sf_cases)){
  plot_observed_cases_polygon_raw(config=params$config, cache=cache, cholera_directory=params$cholera_directory) 
} else{
  warning("disjoint_set_sf_cases is NULL")
}

capFig("Observed case counts by time adjusted for time fraction cases/year")
```

**Area adjusted cases by time:**
```{r areadjustedmap, fig.height=5, fig.width=10, fig.cap=capFig("Area adjusted average observed case counts by time adjusted for time fraction cases/(year * kilometer)")}
if(!is.null(disjoint_set_sf_cases)){
  taxdat::plot_area_adjusted_observed_cases(
    disjoint_set_sf_cases,
    render = T
  )
} else{
  warning("disjoint_set_sf_cases is NULL")
}

```

**Cases unique location periods:**
```{r obsmap, fig.height=5, fig.width=10, fig.cap=capFig("Number of observations by unique observed location periods.")}
if(!is.null(disjoint_set_sf_cases)){
  taxdat::plot_raw_observations(disjoint_set_sf_cases,
                                render = T)
} else{
  warning("disjoint_set_sf_cases is NULL")
}
```


## Covariates

### Population
**Population raster by time slices:**
```{r pop, fig.height=5, fig.width=10, fig.cap=capFig("Population density")}
if(as.character(stringr::str_extract(params$config, "[A-Z]{3}")) == "ZNZ"){
  country_shp <- rgeoboundaries::gb_adm1("TZA")[rgeoboundaries::gb_adm1("TZA")$shapeName %in% 
                                                c("Zanzibar South & Central", "Zanzibar North", "Zanzibar Urban/West"), ]
}else{
  country_shp <- rgeoboundaries::gb_adm0(as.character(stringr::str_extract(params$config, "[A-Z]{3}")))
}

### Get the pltdata
covar_data_filename = file_names["covar"]
covar_cube_output <- taxdat::read_file_of_type(covar_data_filename, "covar_cube_output")
covar_cube <- covar_cube_output$covar_cube
sf_grid <- covar_cube_output$sf_grid
pop_layer <- covar_cube[,,1, drop = F] ## population is always the first layer
covar <- data.frame(covar = unlist(lapply(1:ncol(pop_layer), function(x){
    pop_layer[, x, 1]
  })))
  pltdata <- dplyr::bind_cols(sf_grid, covar)

analysis_years <- lubridate::year(config$start_time):lubridate::year(config$end_time)
pltdata$t<- factor(pltdata$t, labels = analysis_years )

plt<-ggplot2::ggplot()+ggplot2::geom_sf(data = pltdata , ggplot2::aes(fill = covar,
            color = covar)) + ggplot2::scale_fill_viridis_c("Population",
            trans = "log", breaks = c(100, 1000, 10000,
                1e+05), aesthetics = c("colour", "fill"),
            guide = ggplot2::guide_colorbar(title = "Population density [per grid cell]"),
            option = "E", na.value = "white") + ggplot2::theme_bw() +
            ggplot2::theme(legend.position = "bottom",
                legend.text = ggplot2::element_text(angle = 45,hjust = 1, vjust = 1))+
 facet_wrap(~ t)
plt

pop_raster_data<-raster()
for(layer in unique(pltdata$t)){
  empty_raster <- raster::raster(pltdata[which(pltdata$t==layer),], res = max(0.00833333, 0.00833333))#1*1km raster
  pop_raster_data_tmp <- fasterize::fasterize(pltdata[which(pltdata$t==layer),], empty_raster, field = c("covar"))
  pop_raster_data<-stack(pop_raster_data,pop_raster_data_tmp)
}
```


**Table 3. Population by admin level:**
```{r echo = FALSE}
## the rest of this section is added on 11/03/2021, and can be turned into a function in model_evaluation_helpers.R later
## ======================================================================================================================
### Get the pltdata
if(nrow(sf_grid) == prod(dim(pop_layer))){

  ### Use the geo package
  iso_code <- as.character(stringr::str_extract(params$config, "[A-Z]{3}"))
  admin_level <- as.numeric(params$admin_level_for_summary_table)
  if (iso_code == "ZNZ" & admin_level == 1){
    boundary_sf <- rgeoboundaries::gb_adm1("TZA")[rgeoboundaries::gb_adm1("TZA")$shapeName %in% c("Zanzibar South & Central", "Zanzibar North", "Zanzibar Urban/West"), ]
  } else if (iso_code == "ZNZ"){
    stop('Sorry, currently ZNZ only has the admin 1 level shape files available to use, please try again. ')
  } else{
  if (admin_level == 1){
    boundary_sf <- rgeoboundaries::gb_adm1(iso_code)
  }else if (admin_level == 2){
    boundary_sf <- rgeoboundaries::gb_adm2(iso_code)
    warning('The current admin level is set at 2. ')
  }else if (admin_level == 3){
    boundary_sf <- rgeoboundaries::gb_adm3(iso_code)
    warning('The current admin level is set at 3. ')
  }else{
    stop('Error: the current admin level is unnecessarily high or invalid, 
    please check and change the parameters for the country data report before running again. ')
  }
}
    
  ### For loops and make the table
  admin_pop_table <- data.frame(matrix(NA, length(boundary_sf$shapeName), length(unique(pltdata$t)) + 1))
  
  start_year <- as.numeric(stringr::str_extract(stringr::str_extract(params$config, "[A-Z]{3}_[0-9]{4}"), "[0-9]{4}"))
  pltdata$t<-as.numeric(pltdata$t)
  pltdata$t<-as.numeric(pltdata$t-min(pltdata$t))+1
  year_list <- unique(pltdata$t) + (start_year-1)

  if(is.na(start_year)){
  start_year <- as.numeric(stringr::str_extract(params$config, "[0-9]{1,4}"))
  year_list <- unique(pltdata$t) + (start_year-1)

  if(!start_year%in%c(2015,2016,2017,2018,2019)){
      start_year <- as.numeric(stringr::str_extract(params$config, "\\d+(?=.yml)"))
      year_list <- start_year
  }
  }
  
  colnames(admin_pop_table) <- c('adminlevel', year_list)
  admin_pop_table$adminlevel <- boundary_sf$shapeName

    ## across different locations and t

for(layer in 1:raster::nlayers(pop_raster_data)){

    for (locs in admin_pop_table$adminlevel){
      cropped <- raster::crop(pop_raster_data[[layer]], boundary_sf[boundary_sf$shapeName == locs, layer+1], snap = "out")
      masked <- raster::mask(cropped, boundary_sf[boundary_sf$shapeName == locs, layer+1], updatevalue = NA)
      sum_pop <- sum(raster::getValues(masked), na.rm = TRUE)
      admin_pop_table[match(locs, admin_pop_table$adminlevel), layer+1]<-round(sum_pop,4) 
      rm(cropped, masked)
    } 

}

  ### Add a total row, change colnames, and display the table
  total_row <- c('Total', apply(data.frame(admin_pop_table[, -1]), 2, sum))
  admin_pop_table <- rbind(admin_pop_table, total_row)
  
  admin_pop_table %>%
    dplyr::mutate_if(is.numeric, function(x) {format(x , big.mark=",")}) %>%
    kableExtra::kable(col.names = c('Admin Level', year_list)) %>%
    kableExtra::kable_styling(bootstrap_options = c("striped")) %>%
    kableExtra::kable_paper(full_width = F) %>%
    kableExtra::row_spec(nrow(admin_pop_table), bold = T)
  
} else{
  warning("sf_grid has a different number of cells or timepoints than covar_cube")
}
```

### Other covariates
**Covariate rasters:**
```{r covars, fig.height=5, fig.width=8, fig.cap=capFig("Covariate rasters")}
taxdat::plot_raster_covariates(covar_data_filename = file_names["covar"], render = T)
```

## Output maps

```{r analysisyears}
obs_years <- min(lubridate::year(stan_input$sf_cases_resized$TL)):max(lubridate::year(stan_input$sf_cases_resized$TR))
# Runtimes by chain
rstan::get_elapsed_time(model.rand)
```


```{r importcase}
case_raster <- NULL
  case_raster <- taxdat::get_case_raster(preprocessed_data_filename = file_names["data"],
covar_data_filename = file_names["covar"],
model_output_filenames = file_names["stan_output"])
 
  #disaggregate incidence raster to 1*1KM 
  rate_raster <- case_raster %>%
    dplyr::select(dplyr::contains("modeled rates"),id,t,x,y,geom) %>%
    tidyr::gather(dplyr::contains("iterations: Chain"), key = "chain", value = "value") %>%
    dplyr::mutate(chain = stringr::str_replace(chain, "modeled rates", ""),value=value)
  
  empty_raster <- raster::raster(rate_raster, res = max(0.00833333, 0.00833333))#1*1km raster
  disaggregated_rate_raster <- fasterize::fasterize(rate_raster, empty_raster, field = c("value"),by="t")
 

   #disaggregate case raster to 1*1KM 
  case_raster <- case_raster %>%
    dplyr::select(dplyr::contains("modeled cases"),id,t,x,y,geom) %>%
    tidyr::gather(dplyr::contains("iterations: Chain"), key = "chain", value = "value") %>%
    dplyr::mutate(chain = stringr::str_replace(chain, "modeled cases", ""),value=value)
  
  empty_raster <- raster::raster(case_raster, res = max(0.00833333, 0.00833333))#1*1km raster
  disaggregated_case_raster <- fasterize::fasterize(case_raster, empty_raster, field = c("value"),by="t")
 
if(length(unique(pltdata$t))>1){
  disaggregated_case_sf=disaggregated_case_raster%>%as(.,'SpatialPolygonsDataFrame')%>% sf::st_as_sf(.)%>%dplyr::rename("1"=X1,"2"=X2,"3"=X3,"4"=X4,"5"=X5)%>%tidyr::pivot_longer(.,cols=c("1","2","3","4","5"),names_to="t")%>%as.data.frame(.)%>%sf::st_as_sf(.)
  colnames(disaggregated_case_sf)[stringr::str_detect( colnames(disaggregated_case_sf),"value")]=colnames(case_raster)[stringr::str_detect(colnames(case_raster),"value")]
  disaggregated_case_sf$id<-rep(1:(nrow(disaggregated_case_sf)/length(unique(disaggregated_case_sf$t))),each=5)

  disaggregated_rate_sf=disaggregated_rate_raster%>%as(.,'SpatialPolygonsDataFrame')%>% sf::st_as_sf(.)%>%dplyr::rename("1"=X1,"2"=X2,"3"=X3,"4"=X4,"5"=X5)%>%tidyr::pivot_longer(.,cols=c("1","2","3","4","5"),names_to="t")%>%as.data.frame(.)%>%sf::st_as_sf(.)
  colnames(disaggregated_rate_sf)[stringr::str_detect(colnames(disaggregated_rate_sf),"value")]=colnames(rate_raster)[stringr::str_detect(colnames(rate_raster),"value")]
  disaggregated_rate_sf$id<-rep(1:(nrow(disaggregated_rate_sf)/length(unique(disaggregated_rate_sf$t))),each=5)

}  else{
  
  disaggregated_case_sf=disaggregated_case_raster%>%as(.,'SpatialPolygonsDataFrame')%>% sf::st_as_sf(.)
  colnames(disaggregated_case_sf)[stringr::str_detect( colnames(disaggregated_case_sf),"layer")]=colnames(case_raster)[stringr::str_detect(colnames(case_raster),"modeled case")]
  disaggregated_case_sf$id<-rep(1:(nrow(disaggregated_case_sf)/length(unique(disaggregated_case_sf$t))),each=1)

 #single year runs
  disaggregated_rate_sf=disaggregated_rate_raster%>%as(.,'SpatialPolygonsDataFrame')%>% sf::st_as_sf(.)%>%dplyr::rename("1"=X1)%>%tidyr::pivot_longer(.,cols=c("1"),names_to="t")%>%as.data.frame(.)%>%sf::st_as_sf(.)
  colnames(disaggregated_rate_sf)[stringr::str_detect( colnames(disaggregated_rate_sf),"value")]=colnames(case_raster)[stringr::str_detect(colnames(case_raster),"modeled rate")]
  disaggregated_rate_sf$id<-rep(1:(nrow(disaggregated_rate_sf)/length(unique(disaggregated_rate_sf$t))),each=1)
}

  if(all(analysis_years %in% obs_years)){
    message("All analysis years are represented by OCs.")
  } else{
    drop_year_ix <- which(!analysis_years %in% obs_years)
    message(paste(paste(analysis_years[drop_year_ix], collapse = ", "), "are not represented in OCs"))
    if(params$drop_nodata_years){
      message(paste("Dropping", paste(analysis_years[drop_year_ix], collapse = ", "), "from case_raster"))
      case_raster <- dplyr::filter(case_raster, !(t %in% drop_year_ix))
    }
  }
```

### Modeled cases
**Modeled cases raster by time slices:**
```{r caserast, fig.cap=capFig("Modeled cases"), fig.height=5, fig.width=10}
if(!is.null(case_raster)){
 plot_disaggregated_modeled_cases_time_varying(case_raster=case_raster,disaggregated_case_sf=disaggregated_case_sf)
} else{
  warning("case_raster is NULL")
}
```

**Table 4. Modeled cases by admin level and time:**
```{r echo = FALSE}
### Clean up the sf dataset
case_raster_admin<-disaggregated_case_sf
colnames(case_raster_admin)[stringr::str_detect(colnames(case_raster_admin),"modeled case")] <- "value"

### For loops and make the table
admin_case_table <- data.frame(matrix(NA, length(boundary_sf$shapeName), length(unique(case_raster_admin$t)) + 1))
year_list <- unique(as.numeric(case_raster_admin$t)) + (start_year-1)
colnames(admin_case_table) <- c('adminlevel', year_list)
admin_case_table$adminlevel <- boundary_sf$shapeName

for (ts in unique(case_raster_admin$t)){
  ## filter and rasterize
  case_raster_admin_ts <- case_raster_admin %>% filter(t == ts)
  empty_raster <- raster::raster(case_raster_admin_ts, res = res(disaggregated_case_raster))
  raster_data <- fasterize::fasterize(case_raster_admin_ts, empty_raster, field = "value")

  ## across different locations
  for (locs in admin_case_table$adminlevel){
    cropped <- raster::crop(raster_data, boundary_sf[boundary_sf$shapeName == locs, ], snap = "near")
    masked <- raster::mask(cropped, boundary_sf[boundary_sf$shapeName == locs, ], updatevalue = NA)
    sum_case <- sum(raster::getValues(masked), na.rm = TRUE)
    admin_case_table[match(locs, admin_case_table$adminlevel), (match(ts, unique(case_raster_admin$t)) + 1)] <- sum_case
    rm(cropped, masked)
  } 

  ## optimize memory
  rm(case_raster_admin_ts, empty_raster, raster_data)
}

### Add a total row, change colnames, and display the table
total_row <- c('Total', apply(data.frame(admin_case_table[, -1]), 2, sum))
admin_case_table <- rbind(admin_case_table, total_row)
admin_case_table[, -1] <- apply(as.matrix(noquote(admin_case_table[, -1])),  # Using apply function
                                  2,
                                  as.numeric)
admin_case_table$mean_across_years <- apply(admin_case_table[, -1], 1, mean)
admin_case_table <- admin_case_table %>% 
 mutate_if(is.numeric, round, digits=4)

admin_case_table %>%
  dplyr::mutate_if(is.numeric, function(x) {format(x , big.mark=",")}) %>%
  kableExtra::kable(col.names = c('Admin Level', year_list, 'Mean across Years')) %>%
  kableExtra::kable_styling(bootstrap_options = c("striped")) %>%
  kableExtra::kable_paper(full_width = F) %>%
  kableExtra::row_spec(nrow(admin_case_table), bold = T)
```



### Modeled incidence rates
**Modeled incidence rates raster by time slices:**
```{r raterast, fig.cap=capFig("Modeled rates by time"), fig.height=5, fig.width=10}
if(!is.null(case_raster)){
  taxdat::plot_modeled_rates_time_varying(case_raster, render = T)
} else{
  warning("case_raster is NULL")
}
```

**Table 5. Modeled population-weighted incidence rates by admin level and time:**
```{r echo = FALSE}
### Clean up the sf dataset
rate_raster_admin<-disaggregated_rate_sf
colnames(rate_raster_admin)[stringr::str_detect(colnames(rate_raster_admin),"modeled rate")] <- "value"

##### Multiply two rasters together
### For loops and make the table
admin_rate_table <- data.frame(matrix(NA, length(boundary_sf$shapeName), length(unique(rate_raster_admin$t)) + 1))
year_list <- as.numeric(unique(rate_raster_admin$t)) + (start_year-1)
colnames(admin_rate_table) <- c('adminlevel', year_list)
admin_rate_table$adminlevel <- boundary_sf$shapeName

total_w_rate<-c()

for (ts in unique(rate_raster_admin$t)){
  ## the rates raster
  rate_raster_admin_ts <- rate_raster_admin %>% filter(t == ts)
  raster_data_cal_case <- disaggregated_case_raster[[as.numeric(ts)]]

  pop_cropped <- raster::crop(pop_raster_data,disaggregated_rate_raster)
  origin(pop_cropped)<-origin(disaggregated_rate_raster)
  raster_data_pop <- pop_cropped

  ## across different locations
  for (locs in admin_rate_table$adminlevel){
    ## the calculated case raster
    cropped <- raster::crop(raster_data_cal_case, boundary_sf[boundary_sf$shapeName == locs, ], snap = "near")
    masked <- raster::mask(cropped, boundary_sf[boundary_sf$shapeName == locs, ], updatevalue = NA)
    sum_cal_case <- sum(raster::getValues(masked), na.rm = TRUE)
    ## the pop raster
    cropped <- raster::crop(raster_data_pop, boundary_sf[boundary_sf$shapeName == locs, ], snap = "near")
    masked <- raster::mask(cropped, boundary_sf[boundary_sf$shapeName == locs, ], updatevalue = NA)
    sum_pop <- sum(raster::getValues(masked), na.rm = TRUE)
    ## the table
    w_rate <- (sum_cal_case / sum_pop) * 1e4
    admin_rate_table[match(locs, admin_rate_table$adminlevel), (match(ts, unique(rate_raster_admin$t)) + 1)] <- w_rate
    rm(cropped, masked)
  } 

  ## the total weighted rate
  if(exists('total_w_rate')){
    total_w_rate <- c(total_w_rate,
                      sum(raster::getValues(raster_data_cal_case), na.rm = TRUE) / sum(raster::getValues(raster_data_pop), na.rm = TRUE))
  }else{
    total_w_rate <- sum(raster::getValues(raster_data_cal_case), na.rm = TRUE) / sum(raster::getValues(raster_data_pop), na.rm = TRUE)
  }
  
  ## optimize memory
  rm(rate_raster_admin_ts, raster_data_cal_case,raster_data_pop)
  
}

### Add a total row, change colnames, and display the table
total_row <- c('Weighted Total', total_w_rate * 1e4)
admin_rate_table <- rbind(admin_rate_table, total_row)
admin_rate_table[, -1] <- apply(as.matrix(noquote(admin_rate_table[, -1])),  # Using apply function
                                  2,
                                  as.numeric)
admin_rate_table$mean_across_years <- apply(admin_rate_table[, -1], 1, mean)
admin_rate_table <- admin_rate_table %>% 
 mutate_if(is.numeric, round, digits=4)

admin_rate_table %>%
  dplyr::mutate_if(is.numeric, function(x) {format(x , big.mark=",")}) %>%
  kableExtra::kable(col.names = c('Admin Level', year_list, 'Mean across Years')) %>%
  kableExtra::kable_styling(bootstrap_options = c("striped")) %>%
  kableExtra::kable_paper(full_width = F) %>%
  kableExtra::row_spec(nrow(admin_rate_table), bold = T)
```


## Validation

```{r import_modelfidel}
data_fidelity <- NULL
try({
  if(file.exists(file_names["initial_values"])){
  data_fidelity <- taxdat::get_data_fidelity(stan_input_filenames = file_names["stan_input"],
                                          model_output_filenames = file_names["stan_output"])
  
  }else{
    #for old runs without initial_values output files
    stan_input_filenames = file_names["stan_input"]
    model_output_filenames = file_names["stan_output"]
    if (length(stan_input_filenames) != length(model_output_filenames))
    stop("Need to provide same number of stan_input and stan_output files")
  
  rc <- list()
  layer_index <- 1
  for (i in 1:length(model_output_filenames)) {
    filename <- model_output_filenames[i]
    model.rand <- read_file_of_type(filename, "model.rand")
    nchain <- dim(MCMCvis::MCMCchains(model.rand, params='lp__'))[1] / niter_per_chain
    
    stan_data <- read_file_of_type(stan_input_filenames[i], "stan_input")$stan_data
    modeled_cases <- as.array(model.rand)[, , grepl("modeled_cases", names(model.rand)), drop = FALSE]
    modeled_cases_chain_mean <- apply(modeled_cases, c(2, 3), mean)
    actual_cases <- matrix(stan_data$y, nrow(modeled_cases_chain_mean), ncol(modeled_cases_chain_mean), byrow=TRUE)
    dimnames(actual_cases) <- dimnames(modeled_cases_chain_mean)
    modeled_cases_chain_mean <- reshape2::melt(modeled_cases_chain_mean)
    actual_cases <- reshape2::melt(actual_cases)
    actual_cases$censoring <- rep(stan_data$censoring_inds, each = nchain)
    actual_cases$oc_uid <- rep(taxdat::read_file_of_type(stan_input_filenames[i], "stan_input")$sf_cases_resized$OC_UID, 
                               each = nchain) #newly added
    actual_cases$oc_year <- rep(paste0(format(taxdat::read_file_of_type(stan_input_filenames[i], "stan_input")$sf_cases_resized$TL, '%Y'),
                                       "_",
                                       format(taxdat::read_file_of_type(stan_input_filenames[i], "stan_input")$sf_cases_resized$TR, '%Y')),
                               each = nchain) #newly added and updated on 21-12-14
    
    stan_data<-read_file_of_type(file_names["data"],"stan_data")
    obs_tfrac=data.frame(
      obs = stan_data$map_obs_loctime_obs,
      tfrac = stan_data$tfrac
    ) %>%
      dplyr::group_by(obs) %>%
      dplyr::summarize(tfrac = sum(tfrac))
    actual_cases$tfrac<-1
    actual_cases[stringr::str_detect(actual_cases$parameters,"tfrac"),]$tfrac<-rep(obs_tfrac$tfrac,each=nchain)
    
    comparison <- dplyr::left_join(modeled_cases_chain_mean, actual_cases, by = c(chains = "chains", parameters = "parameters"))
    names(comparison)[3:4] <- c("modeled cases", "actual cases")
    rc[[filename]] <- comparison
    names(rc)[[layer_index]] <- paste(
      paste(filename_to_stubs(filename)[2:3], collapse = " "),
      "\niterations: Chain", filename_to_stubs(filename)[5])
    layer_index <- layer_index + 1
  }
  data_fidelity<-rc
}
  
})
```


**Actual observations versus modeled cases scatter plot:**
```{r datafidelity1, fig.cap=capFig("Observations vs. modeled cases"), fig.height=10, fig.width=10}
if(!is.null(data_fidelity)&!config$censoring){
  
  taxdat::plot_model_fidelity_tfrac_adjusted(data_fidelity = data_fidelity,
                                              case_raster = case_raster,
                                              render = T)
} else{
  warning("data_fidelity is NULL")
}
```

```{r datafidelity2, fig.cap=capFig("Observations/tfrac vs. modeled cases/tfrac"), fig.height=10, fig.width=10}
if(!is.null(data_fidelity)){
  
  taxdat::plot_model_fidelity_tfrac_converted(data_fidelity = data_fidelity,
                                              case_raster = case_raster,
                                              render = T)
  
} else{
  warning("data_fidelity is NULL")
}
```


```{r datafidelity3, fig.cap=capFig("Observations vs. modeled cases (tfrac adjusted)"), fig.height=15, fig.width=10}
if(!is.null(data_fidelity)&!config$censoring){
  
  taxdat::plot_model_fidelity_tfrac_adjusted_by_year(data_fidelity = data_fidelity,
                                                      case_raster = case_raster,
                                                      render = T)
  
} else{
  warning("data_fidelity is NULL")
}
```

```{r datafidelity4, fig.cap=capFig("Observations vs. modeled cases"), fig.height=8, fig.width=10}

if(!is.null(data_fidelity)){
  
  taxdat::plot_model_fidelity_tfrac_unadjusted(data_fidelity = data_fidelity,
                                                case_raster = case_raster,
                                                render = T)

} else{
  warning("data_fidelity is NULL")
}

```


**Stan trace plots:**
```{r traceplots, fig.height=8, fig.width=10, fig.cap=capFig("Stan trace plots")}

if(!is.null(model.rand)){
taxdat::plot_chain_convergence(file_names[["stan_output"]],
                               pars =  c("rho", "betas", "log_std_dev_w", "eta"),
                               render = T)
}

```


**Parameter posteriors:**
```{r params, fig.height=6, fig.width=6, fig.cap=capFig("Parameter posteriors")}
if(!is.null(model.rand)){
  rstan::plot(model.rand, pars =  c("rho", "betas", "log_std_dev_w", "eta"))

} else{
  warning("model.rand is NULL")
}
```


**Gelman-Rubin Rhat:**
```{r rhat, fig.height=5, fig.width=10, fig.cap=capFig("Gelman-Rubin Rhat")}
if(!is.null(model.rand)){
  taxdat::plot_rhat(model.rand, render = T)
} else{
  warning("model.rand is NULL")
}
```


**Table 6. Observed and estimates of WHO annual cholera reports:**
```{r WHO output, fig.height=5, fig.width=10, fig.cap = "comparison with WHO Output"}
if(!is.null(sf_cases_resized) & !is.null(model.rand)){
  who_annual_cases <- sf_cases_resized
  chains <- rstan::extract(model.rand)
  who_annual_cases$modeled <- apply(chains$modeled_cases,2,mean)
  who_annual_cases$observed <- who_annual_cases$attributes.fields.suspected_cases # fix me
  who_annual_cases_from_db <- NULL
  try({
    who_annual_cases_from_db <- taxdat::pull_output_by_source(who_annual_cases, "%WHO Annual Cholera Reports%",
                                                              database_api_key_rfile = stringr::str_c(params$cholera_directory, "Analysis/R/database_api_key.R"))
  })
  if(!is.null(who_annual_cases_from_db)) {
    who_annual_cases_from_db %>%
      as.data.frame() %>%
      dplyr::select(OC_UID, TL, TR, observed, modeled) %>%
      dplyr::mutate_if(is.numeric, function(x) {format(round(x) , big.mark=",")}) %>%
      kableExtra::kable(col.names = c("OC id", "start time", "end time", "# Observed cases", "# Modeled Cases")) %>%
      kableExtra::kable_styling(bootstrap_options = c("striped"))
  }

} else{
  warning("sf_cases_resized or model.rand is NULL")
}
```


**Table 7. Estimated cases by chain and time slice:**
```{r cases_chain_table, fig.width=10, fig.cap = "Sum of grid cases by chain and year"}
if(!is.null(model.rand) && !is.null(stan_input)){
  stan_input$sf_grid <- stan_input$sf_grid %>%
    dplyr::ungroup() %>%
    dplyr::select(t,id)
  stan_input$sf_grid[paste('cases','chain',seq_len(nchain),sep='_')] <- cases_chains

  if(params$drop_nodata_years & !all(analysis_years %in% obs_years)){
      drop_year_ix <- which(!analysis_years %in% obs_years)
      message(paste("Dropping", paste(analysis_years[drop_year_ix], collapse = ", "), "from cases_chains"))
      stan_input$sf_grid <- dplyr::filter(stan_input$sf_grid, !(t %in% drop_year_ix))
    }

  sf_grid_wider <- sf::st_drop_geometry(stan_input$sf_grid)

  by_years <- sf_grid_wider %>%
    dplyr::group_by(t) %>%
    dplyr::summarise(dplyr::across(dplyr::contains("cases_chain"), sum)) %>%
    dplyr::mutate(t = as.character(t))
  mai <- by_years %>%
    dplyr::summarise(dplyr::across(dplyr::contains("cases_chain"), mean)) %>%
    dplyr::mutate(t = "mean annual cases")

  dplyr::bind_rows(by_years, mai) %>%
    kableExtra::kable(col.names = c("time slice", paste("chain", 1:nchain))) %>%
    kableExtra::kable_styling(bootstrap_options = c("striped"))

} else{
  warning("stan_input is NULL")
}
```

```{r full country modeled cases, fig.cap = "comparison with WHO Output"}
if(!is.null(sf_cases_resized) & !is.null(model.rand)){
  grid_cases_mean <- apply(chains$grid_cases,2,mean)
  total_cases <- sum(grid_cases_mean)
  print(paste("There are",format(round(total_cases), big.mark=","),"total cases"))

} else{
  warning("chains was not extracted from model.rand")
}
```