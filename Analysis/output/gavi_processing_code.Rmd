---
title: "gavi_processing_code"
output: html_document
params: 
  cholera_directory: "~/cholera-mapping-pipeline"
  config: "configs/config.yml"
  old_runs: FALSE
  single_year: FALSE
---

```{r setup, include=FALSE, dev="CairoPNG"}
knitr::opts_chunk$set(
  echo = FALSE,
  dev = "CairoPNG",
  error = FALSE,
  fig.align = "center",
  message = TRUE,
  warning = TRUE
)

library(stringr)
library(dplyr)
library(magrittr)
library(purrr)
library(readr)
library(ggplot2)
library(kableExtra)
library(taxdat)
library(sf)
library(raster)
library(stars)

### other new packages (mainly for "rgeoboundaries")
chooseCRANmirror(ind = 77)

package_list <- c(
  "fasterize",
  "remotes",
  "rgeoboundaries"
)

for (package in package_list) {
  if (!require(package = package, character.only = T)) {
    if (package == "rgeoboundaries") {
      try({
        remotes::install_gitlab("dickoa/rgeoboundaries")
        remotes::install_github("wmgeolab/rgeoboundaries")
      })
    } else {
      install.packages(pkgs = package)
      library(package = package, character.only = T)
    }
  }
}
```

```{r load processing functions}
## Method1: create summary values for each layer across cells, then summarize across layers to get CIs.
# for each layer, group the cells by incidence rates (mild, moderate, and high incidence areas)

#' @name crop_to_shapefile
#' @title crop_to_shapefile: crop the raster with country shapefile
#' @param raster: raster file
#' @param shapefile: the country or location shapefile
#' @param snap: in which direct the extext should be aligned to
#' @return cropped and maksed raster
crop_to_shapefile <- function(raster, shapefile, snap) {
  raster_cropped <- raster::crop(raster, extent(shapefile), snap = snap)
  raster_cropped <- raster::mask(raster_cropped, shapefile)
  return(raster_cropped)
}

# Generalize this function to different year?
#' Get 2017 population
#'
#' @param sf_grid the sf_grid object from the stan_input file
#'
#' @return a new sf_grid object with a column for the 2017 population
#'
get_pop2017 <- function(sf_grid) {
  # Connect to database
  conn <- taxdat::connect_to_db(Sys.getenv("USER"))

  # Pul the 2017 population data
  pop2017 <- rpostgis::pgGetRast(conn,
    name = c("covariates", "pop_1_years_20_20"),
    band = which(2000:2020 == 2017)
  )

  # Extract the values at the centroids of sf_grid
  sf_grid$pop2017 <- raster::extract(pop2017, sf::st_centroid(sf_grid))

  DBI::dbDisconnect(conn)

  return(sf_grid)
}

#' @name get_rate_raster
#' @title get_rate_raster
#' @description get rate raster for each layer
#' @param preprocessed_data_filename
#' @param covar_data_filename
#' @param model_output_filenames
#' @return rate_raster
get_rate_raster <- function(covar_data_filename,
                            model_output_filenames,
                            stan_input_filenames,
                            if_single_year_run,
                            res = c(0.1666667, 0.1666667),
                            starting_year = 2015) {
  # load model output data
  covar_cube_output <- read_file_of_type(covar_data_filename, "covar_cube_output")
  rate_raster <- covar_cube_output$sf_grid
  non_na_gridcells <- taxdat::get_non_na_gridcells(covar_data_filename)
  rate_raster <- rate_raster[non_na_gridcells, ]
  model.rand <- read_file_of_type(model_output_filenames, "model.rand")
  niter_per_chain <- dim(MCMCvis::MCMCchains(model.rand, params = "lp__", chain_num = 1))[1]

  # average modeled cases across chains
  modeled_cases <- as.array(model.rand)[, , grepl("grid_case", names(model.rand)), drop = FALSE]
  modeled_cases_mean_by_grid_layer_tmp <- as.data.frame(t(apply(modeled_cases, c(1, 3), mean))) %>%
    mutate(id = seq_len(dim(modeled_cases)[3]))

  # subset years with obervations and remove years without obsevations (drop some years)
  stan_input <- read_file_of_type(stan_input_filenames, "stan_input")
  if (params$single_year == FALSE) {
    obs_years <- (nrow(modeled_cases_mean_by_grid_layer_tmp) / length(unique(lubridate::year(stan_input$sf_cases_resized$TL), lubridate::year(stan_input$sf_cases_resized$TR)))) * ((unique(c(lubridate::year(stan_input$sf_cases_resized$TL), lubridate::year(stan_input$sf_cases_resized$TR)))) - starting_year)

    modeled_cases_mean_by_grid_layer_tmp1 <- data.frame()
    for (row_idx in unique(obs_years)) {
      tmp <- modeled_cases_mean_by_grid_layer_tmp[(row_idx + 1):(row_idx + nrow(modeled_cases_mean_by_grid_layer_tmp) / length(unique(lubridate::year(stan_input$sf_cases_resized$TL), lubridate::year(stan_input$sf_cases_resized$TR)))), 1:niter_per_chain]

      if (length(modeled_cases_mean_by_grid_layer_tmp1) == 0) {
        modeled_cases_mean_by_grid_layer_tmp1 <- tmp
      } else {
        modeled_cases_mean_by_grid_layer_tmp1 <- cbind(modeled_cases_mean_by_grid_layer_tmp1, tmp)
      }
    }
    modeled_cases_mean_by_grid_layer <- modeled_cases_mean_by_grid_layer_tmp1
  } else {
    modeled_cases_mean_by_grid_layer_tmp1 <- modeled_cases_mean_by_grid_layer_tmp
  }

  # estimate 2017 population data from the covariate database
  stan_input <- read_file_of_type(stan_input_filenames, "stan_input")
  pop_sf_grid <- stan_input$sf_grid
  pop_sf_grid_2017 <- get_pop2017(pop_sf_grid)

  # combine the population estimates into case raster
  modeled_cases_mean_by_grid_layer$pop2017 <- pop_sf_grid_2017[1:nrow(modeled_cases_mean_by_grid_layer), ]$pop2017

  modeled_rates_mean_by_grid_layer <- modeled_cases_mean_by_grid_layer
  modeled_rates_mean_by_grid_layer[str_detect(colnames(modeled_rates_mean_by_grid_layer), ".*[0-9].*")] <- modeled_cases_mean_by_grid_layer[str_detect(colnames(modeled_cases_mean_by_grid_layer), ".*[0-9].*")] / modeled_cases_mean_by_grid_layer$pop2017
  modeled_rates_mean_by_grid_layer$id <- 1:nrow(modeled_rates_mean_by_grid_layer)

  rate_raster <- merge(rate_raster[1:length(unique(rate_raster$geom)), ], modeled_rates_mean_by_grid_layer, by = "id")

  colnames(rate_raster)[str_detect(colnames(rate_raster), ".*[0-9].*") & !colnames(rate_raster) %in% "pop2017"] <- paste0("layer", seq_len(length(unique(lubridate::year(stan_input$sf_cases_resized$TL), lubridate::year(stan_input$sf_cases_resized$TR))) * dim(modeled_cases)[1]))

  rate_raster <- rate_raster[, str_detect(colnames(rate_raster), ".*[0-9].*") & !colnames(rate_raster) %in% "pop2017"]

  raster_2020 <- raster::raster(rate_raster, res = res)

  for (layer_idx in seq_len(ncol(rate_raster) - 1)) {
    layer_value <- rate_raster[, layer_idx]

    # empty raster
    single_layer <- raster::raster(rate_raster, res = res)
    # assign rate values into the raster
    single_rate_raster_2020 <- fasterize::fasterize(layer_value, single_layer, field = paste0("layer", layer_idx))

    raster_2020 <- stack(raster_2020, single_rate_raster_2020)
    rm(single_rate_raster_2020)
    gc()
  }
  names(raster_2020) <- colnames(rate_raster)[-ncol(rate_raster)]

  return(raster_2020)
}

#' @name aggregate_affected_pop_across_cells
#' @title aggregate_affected_pop_across_cells: aggregate proportion of population living in each incidence group across cells for each layer
#' @param pop_raster_cropped: 1*1 KM population raster cropped by crop_to_shapefile function
#' @param rate_raster_cropped: 1*1 KM rate_raster (disaggregated from 20*20 KM rater raster) cropped by crop_to_shapefile function
#' @param threshold_list: the threshold to determine mild/moderate/high incidence areas
#' @return results_by_layer
aggregate_affected_pop_across_cells <- function(pop_raster_cropped, rate_raster_cropped, threshold_list) {
  threshold_list <- threshold_list[order(threshold_list, decreasing = T)]
  pop_prop <- as.data.frame(matrix(NA, nrow = 1, ncol = length(unique(threshold_list))))
  names(pop_prop) <- paste0(">=", threshold_list)
  for (threshold_idx in seq_len(length(threshold_list))) {
    pop_prop[, threshold_idx] <-
      100 * sum(values(pop_raster_cropped)[values(rate_raster_cropped) >= threshold_list[threshold_idx]], na.rm = T) /
        sum(values(pop_raster_cropped), na.rm = T)
  }
  pop_prop <- t(t(cbind(0, pop_prop)) - dplyr::lag(t(cbind(0, pop_prop))))[, -1]
  return(pop_prop)
}

#' @name aggregate_affected_pop_across_layers
#' @title aggregate_affected_pop_across_layers: estimate the CI of the proportion of population living in each incidence group across layers
#' @param pop_prop: aggregated population by incidence category for all layers
#' @param probability_cutoffs: the probability cutoffs for distributions
#' @param include_mean: whether to include mean value
#' @param calculate_disjoint_values: whether to return disjoint statistics across layers
#' @return s
aggregate_affected_pop_across_layers <- function(pop_prop, probability_cutoffs, include_mean = TRUE, calculate_disjoint_values = TRUE) {
  probability_distribution <- apply(pop_prop, 2, quantile, probability_cutoffs)
  if (include_mean) {
    mean_values <- apply(pop_prop, 2, mean)
  }
  return(rbind(mean_values, probability_distribution))
}

#' @name get_pop_at_risk
#' @title get_pop_at_risk
#' @param pop_raster: 1*1 KM population raster
#' @param rate_raster: 1*1 KM rate_raster (disaggregated from 20*20 KM rater raster)
#' @param country_shp: country shapefile
#' @param threshold_list: the threshold to determine mild/moderate/high incidence areas
#' @param include_mean: parameter in across_layer_aggregator function (whether to include mean values)
#' @param calculate_disjoint_values: parameter in across_layer_aggregator function (whether to return disjoint statistics across layers)
#' @param within_layer_aggregator: the function to aggregate cells within one layer
#' @param across_layer_aggregator: the function to aggregate across layers
#' @return
get_pop_at_risk <- function(pop_raster_cropped,
                            rate_raster_cropped,
                            threshold_list = c(0.001, 0.0001, 0.00001),
                            include_mean = TRUE,
                            calculate_disjoint_values = TRUE,
                            within_layer_aggregator = aggregate_affected_pop_across_cells,
                            across_layer_aggregator = aggregate_affected_pop_across_layers,
                            probability_cutoffs = c(0.025, 0.5, 0.975)) {
  results_by_layer <- list()
  for (layer_idx in seq_len(nlayers(rate_raster_cropped))) {
    results_by_layer[[layer_idx]] <- within_layer_aggregator(
      pop_raster_cropped = pop_raster_cropped,
      rate_raster_cropped = rate_raster_cropped[[layer_idx]],
      threshold_list = threshold_list
    )
  }
  pop_prop <- do.call("rbind", results_by_layer)
  return(across_layer_aggregator(
    pop_prop = pop_prop,
    probability_cutoffs = probability_cutoffs,
    include_mean = include_mean,
    calculate_disjoint_values = calculate_disjoint_values
  ))
}
```

```{r load data and running script}
config <- yaml::read_yaml(paste0(params$cholera_directory, params$config))
file_names <- taxdat::get_filenames(config, params$cholera_directory)
# update the filenames for old runs
if (params$old_runs) {
  file_names[["stan_output"]] <- stringr::str_remove(file_names[["stan_output"]], "iv-wN-cwN-csF-teT-teaF-weF.")
  file_names[["stan_output"]] <- stringr::str_remove(file_names[["stan_output"]], "-F")
}

# shapefile imported
iso_code <- as.character(stringr::str_extract(params$config, "[A-Z]{3}"))
shapefile <- rgeoboundaries::gb_adm0(iso_code)

# rate raster
rate_raster_2020 <- get_rate_raster(
  covar_data_filename = file_names[["covar"]],
  model_output_filenames = file_names[["stan_output"]],
  stan_input_filenames = file_names[["stan_input"]],
  if_single_year_run = params$single_year
)
rate_raster_2020_cropped <- crop_to_shapefile(raster = rate_raster_2020, shapefile = shapefile, snap = "near")
rm(rate_raster_2020)
gc()

# pop raster
stan_input <- read_file_of_type(file_names[["stan_input"]], "stan_input")
pop_sf_grid <- stan_input$sf_grid
pop_sf_grid_2017 <- get_pop2017(pop_sf_grid)
pop_sf_grid_2017 <- pop_sf_grid_2017[1:length(unique(pop_sf_grid_2017$geom)), ]
empty_pop_raster <- raster::raster(pop_sf_grid_2017, res = c(0.1666667, 0.1666667))

# assign pop values into the raster
pop_raster_2017 <- fasterize::fasterize(pop_sf_grid_2017, empty_pop_raster, field = "pop2017")

pop_raster_2017_cropped <- crop_to_shapefile(raster = pop_raster_2017, shapefile = shapefile, snap = "near")

rm(pop_raster_2017)
gc()
```

```{r processing}
table <- get_pop_at_risk(
  pop_raster_cropped = pop_raster_2017_cropped,
  rate_raster_cropped = rate_raster_2020_cropped,
  res = c(0.1666667, 0.1666667), # 20*20KM
  threshold_list = c(0.001, 0.0001, 0.00001),
  include_mean = TRUE,
  calculate_disjoint_values = TRUE,
  within_layer_aggregator = aggregate_affected_pop_across_cells,
  across_layer_aggregator = aggregate_affected_pop_across_layers,
  probability_cutoffs = c(0.025, 0.5, 0.975)
)

if (params$single_year) {
  year_list <- str_sub(params$config, -8, -5)
} else {
  year_list <- "2015_2019"
}

filename <- paste0("final_table", iso_code, year_list, ".csv")
write.csv(table, filename)
kableExtra::kable(table)
```
